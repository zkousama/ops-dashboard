services:
  # 1. the victim (metrics source)
  node_exporter:
    image: prom/node-exporter:latest
    container_name: ops_exporter
    ports:
      - "9100:9100"
    restart: always

  # 2. the watcher (database)
  prometheus:
    image: prom/prometheus:latest
    container_name: ops_prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
    depends_on:
      - node_exporter

  # 3. the brain (python api)
  backend:
    build: ./backend
    container_name: ops_brain
    ports:
      - "8000:8000"
    pid: host
    environment:
      - PROMETHEUS_URL=http://prometheus:9090
      - API_SECRET=my-super-secret-key-123  # shared secret for the kill switch
    depends_on:
      - prometheus
    volumes:
      - ./backend:/app              # mirror local folder for hot reload
      - /app/venv                   # keep container venv isolated
      - /app/__pycache__            # ignore cache
      - ops_brain_data:/app/data    # persist the ai model here
    # use 'reload' so we see python changes instantly
    command: uvicorn main:app --host 0.0.0.0 --port 8000 --reload

  # 4. the face (next.js ui)
  frontend:
    build: ./frontend
    container_name: ops_face
    ports:
      - "3000:3000"
    environment:
      - NEXT_PUBLIC_API_URL=http://localhost:8000
      - NEXT_PUBLIC_API_SECRET=my-super-secret-key-123 # frontend needs this to authorize requests
    depends_on:
      - backend
    volumes:
      - ./frontend:/app             # mirror local folder
      - /app/node_modules           # keep container node_modules isolated
      - /app/.next                  # ignore build artifacts
    command: npm run dev

# persist the ai model even if containers crash
volumes:
  ops_brain_data: